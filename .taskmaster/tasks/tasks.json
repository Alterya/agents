{
  "master": {
    "tasks": [
      {
        "id": 13,
        "title": "Project Scaffolding & Dependency Definition",
        "description": "Create repository, isolate Python 3.11 environment and lock core dependencies for all modules of the Daily Alert Summary Agent.",
        "details": "• Initialise git repo and add standard .gitignore (Python, venv, secrets)\n• pyproject.toml (preferred) or requirements.txt with pinned libs:\n  - python 3.11\n  - httpx==0.27.0 (2024-05)\n  - APScheduler==3.10.4 (Jerusalem TZ handled by pytz)\n  - python-dotenv==1.0.1\n  - pydantic==2.7.0 for config validation\n  - loguru==0.7.2\n  - backoff==2.2.1\n  - tzdata==2024.1 (if system zoneinfo missing)\n  - pytest==8.2.0, pytest-asyncio==0.23.6 (dev)\n• Directory layout:\n  src/\n    alert_agent/\n      __init__.py\n      config.py\n      scheduler.py\n      collector.py\n      ai_processor.py\n      summary.py\n      notifier.py\n      orchestrator.py\n  tests/\n• Pre-commit hooks: black==24.4.2, isort==5.13.2, mypy==1.10.0\n",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize Git repository and baseline .gitignore",
            "description": "Create the project’s VCS foundation and ensure sensitive or transient files are ignored.",
            "dependencies": [],
            "details": "• Run `git init` in project root.\n• Add a comprehensive .gitignore covering Python bytecode, virtual-env directories, OS files, IDE configs, and secret files (.env, *.pem).\n• Commit initial empty repository state with message “chore: initial repo & .gitignore”.\n<info added on 2025-07-30T10:56:16.181Z>\n• Completed implementation: repository confirmed initialized, .gitignore replaced with Python-centric patterns (bytecode, venv, dist/test artefacts, secrets, OS & IDE files) and committed as “chore: initial repo & .gitignore” (hash 46585c2).  \n• Verification: repository contains exactly one commit; ignored file check passes for all specified patterns.  \n• Subtask marked complete; advance to 13.2 to scaffold canonical src/ and tests/ directories.\n</info added on 2025-07-30T10:56:16.181Z>",
            "status": "done"
          },
          {
            "id": 2,
            "title": "Create canonical directory structure for code and tests",
            "description": "Lay out src/ and tests/ folders with required module stubs.",
            "dependencies": [
              "13.1"
            ],
            "details": "• Generate folder tree:\n  src/alert_agent/ (__init__.py, config.py, scheduler.py, collector.py, ai_processor.py, summary.py, notifier.py, orchestrator.py)\n  tests/ (empty __init__.py)\n• Add placeholder docstrings in each module to pass import.\n• Commit as “chore: scaffold package layout”.\n<info added on 2025-07-30T11:00:04.070Z>\n• Scaffolding finished: src/alert_agent/ and tests/ directories created with all eight module files plus tests/__init__.py (9 files, ~230 LOC).  \n• Each module contains placeholder docstrings, function stubs, and __all__ exports where applicable.  \n• Changes committed under hash e09d9b6 with message “chore: scaffold package layout”.  \n• Subtask 13.2 now complete; hand-off to 13.3 for pyproject.toml dependency manifest.\n</info added on 2025-07-30T11:00:04.070Z>",
            "status": "done"
          },
          {
            "id": 3,
            "title": "Author dependency manifest with pinned versions",
            "description": "Define Python 3.11 requirement and lock library versions through pyproject.toml (preferred) or requirements.txt.",
            "dependencies": [
              "13.1"
            ],
            "details": "• Write pyproject.toml using PEP-621 metadata and `[project.dependencies]` section listing exact versions for httpx, APScheduler, python-dotenv, pydantic, loguru, backoff, tzdata, and optional `[project.optional-dependencies.dev]` for pytest/pytest-asyncio.\n• Include build-system table using `hatchling` or `setuptools`.\n• Add explanatory comments on version pin dates.\n• Commit as “feat: dependency manifest”.\n<info added on 2025-07-30T11:57:32.256Z>\n• Dependency manifest finalized via Poetry: created pyproject.toml targeting Python 3.10, declaring pinned production deps (httpx 0.27.0, APScheduler 3.10.4, python-dotenv 1.0.1, pydantic 2.7.0, loguru 0.7.2, backoff 2.2.1, tzdata 2024.1) with dated inline comments.  \n• Added comprehensive development group: pytest 8.2.0, pytest-asyncio 0.23.6, black 24.4.2, isort 5.13.2, mypy 1.10.0, pre-commit, coverage.  \n• Switched build-system to Poetry (poetry-core backend) and populated `[tool.poetry]` metadata, dependency tables, and `scripts` exposing `alert-agent` CLI.  \n• Embedded tool configs (black, isort, mypy, pytest, coverage) within pyproject and set package layout to `src/alert_agent`.  \n• Manifest committed as `feat: dependency manifest` (hash bafe20b).  \n• Subtask complete; hand-off to 13.4 for Poetry virtual-env creation and lockfile generation.\n</info added on 2025-07-30T11:57:32.256Z>",
            "status": "done"
          },
          {
            "id": 4,
            "title": "Create isolated Python 3.11 virtual environment and lock deps",
            "description": "Provision environment, install and freeze exact versions for reproducibility.",
            "dependencies": [
              "13.1",
              "13.3"
            ],
            "details": "• Use `python3.11 -m venv .venv` (or pyenv + virtualenv).\n• Activate and run `pip install -e .[dev]`.\n• Generate `requirements-lock.txt` via `pip freeze > requirements-lock.txt` or rely on poetry/rye lock file.\n• Document activation instructions in README.\n• Commit as “chore: env setup & deps lock”.\n<info added on 2025-07-30T12:03:47.966Z>\n• Environment provisioned with Poetry: `poetry env use python3.10` and `poetry install` (42 packages resolved and installed)  \n• Syntax fixes applied to pyproject.toml (escaped coverage paths)  \n• Generated and committed 72 KB `poetry.lock` for deterministic builds  \n• Verified key imports, timezone handling, and package export integrity  \n• Extended README with setup instructions, Poetry workflow, and architecture overview  \n• Changes committed as “chore: env setup & deps lock” (dcba130) – subtask ready to hand off to 13.5\n</info added on 2025-07-30T12:03:47.966Z>",
            "status": "done"
          },
          {
            "id": 5,
            "title": "Configure developer tooling: pre-commit hooks & linters",
            "description": "Automate code formatting and static analysis for every commit.",
            "dependencies": [
              "13.1",
              "13.3",
              "13.4"
            ],
            "details": "• Add `.pre-commit-config.yaml` pins: black==24.4.2, isort==5.13.2, mypy==1.10.0.\n• Run `pre-commit install` inside venv.\n• Update pyproject.toml with tool configs for black and isort (line length 100, known_first_party alert_agent).\n• Commit as “chore: pre-commit & lint setup”.\n<info added on 2025-07-30T12:19:38.438Z>\n✅ COMPLETED  \n\n• Added fully-pinned `.pre-commit-config.yaml` (black 24.4.2, isort 5.13.2, mypy 1.10.0) and installed hooks with `poetry run pre-commit install`.  \n• Enabled additional quality checks: whitespace/EOF cleanup, merge-conflict detection, YAML/TOML/JSON validation, Bandit security scan (tests/ excluded), Python debug-statement blocker.  \n• Extended `pyproject.toml` with matching black/isort settings (line-length 100, profile=black, known_first_party=alert_agent).  \n• Applied type-annotation fixes across 7 modules; all mypy checks now pass.  \n• Verified hook suite: black formats, isort orders, mypy validates, CI exits 0; 34 files auto-formatted on first commit.  \n• Commit recorded as `chore: pre-commit & lint setup` (hash 8af0a9f).  \n\nSubtask 13.5 is now complete; ready to move to 13.6 (cleanup & code organisation).\n</info added on 2025-07-30T12:19:38.438Z>",
            "status": "done"
          },
          {
            "id": 6,
            "title": "Cleanup and Code Organization",
            "description": "Remove temporary files, organize imports, and ensure clean code structure",
            "details": "<info added on 2025-07-30T12:22:24.652Z>\nCompleted cleanup and code organization:\n\n• Removed unused alerts_summery directory  \n• Imports, formatting, and type hints all validate clean (isort, black, mypy)  \n• No temporary or cache files outside .venv; structure conforms to src/package layout  \n• Repository working tree is clean; pre-commit hooks all pass  \n\nValidated directory tree:  \n  src/alert_agent/ (8 modules)  \n  tests/  \n  .venv/ (git-ignored)  \n  .taskmaster/  \n  .cursor/  \n\nCommitted as “chore: cleanup and code organization” (hash 461b216). Subtask 13.6 is finished and ready to hand off to Quality Gate (13.7).\n</info added on 2025-07-30T12:22:24.652Z>",
            "status": "done",
            "dependencies": [
              "13.1",
              "13.2",
              "13.3",
              "13.4",
              "13.5"
            ],
            "parentTaskId": 13
          },
          {
            "id": 7,
            "title": "Quality Gate: Tests and Linting",
            "description": "Run comprehensive tests and linting checks to ensure code quality standards",
            "details": "<info added on 2025-07-30T12:30:14.628Z>\nQuality Gate completed and documented:\n\n• Implemented tests/test_basic.py with four foundational checks (package import, individual module import, metadata, placeholder callability).  \n• Added pytest-cov; current baseline coverage 57 %.  \n• All tooling clean: pytest (4 / 4), mypy (8 files, 0 issues), black, isort, bandit, and pre-commit hooks.  \n• Optimised mypy/pre-commit configs—code under src/ only, tests isolated with ignore_missing_imports.  \n• Manual verification confirms package imports, seven modules present, core deps functional, version 0.1.0 correct.  \n• Committed under hash 7d3b438: “feat: add comprehensive test suite and complete quality gate”.\n\nSubtask 13.7 now satisfies quality gate requirements; ready to advance to dependency research (13.8).\n</info added on 2025-07-30T12:30:14.628Z>",
            "status": "done",
            "dependencies": [
              "13.6"
            ],
            "parentTaskId": 13
          },
          {
            "id": 8,
            "title": "Context7 MCP Research: External Package Dependencies",
            "description": "Use Context7 MCP to research and validate external Python packages and dependencies",
            "details": "<info added on 2025-07-30T12:33:46.980Z>\nContext7 MCP research completed and external dependencies validated.\n\nDependencies approved\n• httpx==0.27.0 – async-first client with connection pooling, HTTP/2, robust timeout handling.  \n• pydantic==2.7.0 – high-performance data/config validation, rich type support, strong community.  \n• APScheduler==3.10.4 – Jerusalem-aware scheduling, sync/async APIs, clean shutdown hooks.\n\nKey findings\n• All versions current, stable and free of known CVEs; licences compatible.  \n• Integration patterns verified for our async architecture (Grafana polling, Slack posting).  \n• Performance characteristics meet requirements; community support is strong.\n\nImplementation notes\n• Perform HTTP calls with `async with httpx.AsyncClient()` and add backoff retries.  \n• Define configuration models using Pydantic `ConfigDict` and custom validators.  \n• Start APScheduler with `timezone=\"Asia/Jerusalem\"` and ensure graceful shutdown via context manager.\n\nOutcome\n• Dependency list in parent task is confirmed; lock versions in pyproject/requirements.  \n• Research phase finished—subtask 13.8 can be closed and work proceeds to Task 14.\n</info added on 2025-07-30T12:33:46.980Z>",
            "status": "done",
            "dependencies": [
              "13.7"
            ],
            "parentTaskId": 13
          }
        ]
      },
      {
        "id": 14,
        "title": "Centralised Configuration & Secret Management",
        "description": "Implement environment & YAML driven configuration loader with validation.",
        "details": "• .env template keys: GRAFANA_URL, GRAFANA_TOKEN, OPENROUTER_API_KEY, SLACK_BOT_TOKEN, SLACK_CHANNEL_ID\n• config.yaml defaults: schedule_time: \"10:00\", timezone: \"Asia/Jerusalem\", lookback_hours: 24, openrouter: {model: \"anthropic.claude-4-sonnet\", temperature: 0.2, max_tokens: 2048}\n• Use python-dotenv to load .env → os.environ. Use pydantic BaseModel to validate & expose strongly-typed Config object.\n• Allow override via CLI flags/environment hierarchy.\n• Example:\n```\nclass Settings(BaseSettings):\n    grafana_url: AnyHttpUrl\n    grafana_token: SecretStr\n    ...\n    class Config: env_file = \".env\", env_file_encoding = \"utf-8\"\n```\n",
        "priority": "medium",
        "dependencies": [
          13
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create .env template and environment loader",
            "description": "Draft a .env.example file containing all required keys and implement logic that uses python-dotenv to load variables into os.environ at application start-up.",
            "dependencies": [],
            "details": "Keys: GRAFANA_URL, GRAFANA_TOKEN, OPENROUTER_API_KEY, SLACK_BOT_TOKEN, SLACK_CHANNEL_ID. Provide helper load_dotenv() call in a dedicated config/__init__.py executed before any settings access.\n<info added on 2025-07-30T14:30:44.320Z>\nCompleted implementation. Added comprehensive .env.example containing GRAFANA_MCP_BASE_URL, GRAFANA_MCP_TOKEN, OPENROUTER_API_KEY, SLACK_BOT_TOKEN, SLACK_CHANNEL_ID plus optional advanced settings; committed to repo while .env stays git-ignored.\n\nIntroduced load_config() helper in src/alert_agent/config.py that wraps python-dotenv’s load_dotenv with smart discovery across common paths and override=False, preserving existing env vars.\n\nsrc/alert_agent/__init__.py now invokes load_config() at import time, guaranteeing variables are loaded before any Settings access.\n\nVariable precedence: CLI > process env > .env file > hard-coded defaults.\n</info added on 2025-07-30T14:30:44.320Z>",
            "status": "in-progress"
          },
          {
            "id": 2,
            "title": "Define Pydantic Settings model with validation",
            "description": "Create Settings(BaseSettings) class that validates required secrets and typed URLs, incorporates default values, and exposes a singleton Config object.",
            "dependencies": [
              "14.1"
            ],
            "details": "Include nested OpenRouterConfig model. Use SecretStr for tokens. Configure env_file='.env', env_file_encoding='utf-8'.\n<info added on 2025-07-30T14:36:59.491Z>\nImplementation completed with secure token handling:\n\n• SecretStr imported and applied to all sensitive fields:\n  - GrafanaConfig.token\n  - SlackConfig.bot_token\n  - AIConfig.openrouter_api_key\n• Token validators refactored to use SecretStr.get_secret_value(); new validate_api_key added to AIConfig.\n• All original nested models, URL validations and defaults retained.\n• AppConfig still points to .env with utf-8 encoding.\n• All tests, type-checks and pre-commit hooks pass, confirming backward-compatible integration.\n</info added on 2025-07-30T14:36:59.491Z>",
            "status": "in-progress"
          },
          {
            "id": 3,
            "title": "Implement YAML configuration loader and merge logic",
            "description": "Load config.yaml, apply defaults, and merge with environment variables according to precedence: CLI > ENV > YAML > code defaults.",
            "dependencies": [
              "14.1",
              "14.2"
            ],
            "details": "Use ruamel.yaml or PyYAML to parse, then pass merged dict to Settings(**kwargs) for validation.\n<info added on 2025-07-30T14:45:58.670Z>\nImplementation complete:\n\n• Added PyYAML (6.0.1) to prod deps and types-PyYAML to dev deps, updated lockfile  \n• Introduced config.yaml.example with fully documented defaults covering app, grafana, slack, openrouter, scheduler, logging and feature flags  \n• Implemented load_yaml_config()  \n  – Safe YAML parsing (yaml.safe_load, utf-8) with smart discovery in common paths  \n  – Graceful handling of absent file and detailed parse errors  \n  – Converts nested keys to ENV format (e.g. grafana.timeout_seconds → GRAFANA_TIMEOUT_SECONDS)  \n• Extended load_config() merge pipeline  \n  1. YAML (lowest) → env (non-destructive)  \n  2. .env via python-dotenv  \n  3. Pydantic Settings(**merged) for validation  \n  – Correct bool/type casting, precedence: ENV > YAML > code defaults  \n• All quality gates pass (black, isort, mypy, bandit, pre-commit) and CLI behaviour verified  \n• Backwards compatible with existing ENV-only setups and ready for CLI overrides in 14.4\n</info added on 2025-07-30T14:45:58.670Z>",
            "status": "in-progress"
          },
          {
            "id": 4,
            "title": "Add CLI override interface",
            "description": "Integrate argparse/typer command-line flags to override any Settings field and allow custom YAML path specification.",
            "dependencies": [
              "14.3"
            ],
            "details": "Expose --grafana-url, --schedule-time, --config-path, etc. Convert CLI args to dict and feed into merge chain.",
            "status": "in-progress"
          },
          {
            "id": 6,
            "title": "Cleanup and Code Organization",
            "description": "Remove temporary files, organize imports, and ensure clean code structure",
            "details": "",
            "status": "pending",
            "dependencies": [
              "14.1",
              "14.2",
              "14.3",
              "14.4"
            ],
            "parentTaskId": 14
          },
          {
            "id": 8,
            "title": "Context7 MCP Research: External Package Dependencies",
            "description": "Use Context7 MCP to research and validate external Python packages and dependencies",
            "details": "",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 14
          }
        ]
      },
      {
        "id": 15,
        "title": "Jerusalem-Aware Daily Scheduler",
        "description": "Set up APScheduler job that triggers orchestrator at 10:00 AM Asia/Jerusalem with DST correctness.",
        "details": "• Use `AsyncIOScheduler(timezone=\"Asia/Jerusalem\")`.\n• Job definition example:\n```\nscheduler.add_job(run_job, 'cron', hour=10, minute=0, misfire_grace_time=300)\n```\n• Provide CLI `python -m alert_agent.scheduler --run_once` for local test.\n• Persist scheduler in orchestrator with graceful shutdown signals (SIGINT/SIGTERM).\n",
        "priority": "high",
        "dependencies": [
          14
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Timezone & Environment Preparation",
            "description": "Ensure the application can resolve \"Asia/Jerusalem\" correctly on every platform, including Docker Alpine images where zoneinfo may be absent.",
            "dependencies": [],
            "details": "• Add tzdata==2024.1 to dependencies and document that it must be installed in prod images.\n• Create utility function `get_jlm_tz()` that returns `zoneinfo.ZoneInfo(\"Asia/Jerusalem\")` and falls back to `pytz` when necessary.\n• Validate DST behaviour by printing offsets for known summer/winter dates during boot.\n• Expose this utility in `alert_agent.utils.time` for reuse by scheduler and tests.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "AsyncIOScheduler Initialization",
            "description": "Create a scheduler module that builds and starts an `AsyncIOScheduler` instance using the Jerusalem timezone utility.",
            "dependencies": [
              "15.1"
            ],
            "details": "• File: `alert_agent/scheduler/core.py`.\n• Function `create_scheduler()` returns a started `AsyncIOScheduler(timezone=get_jlm_tz())`.\n• Configure default job stores and executors (ThreadPoolExecutor max_workers=10).\n• Expose singleton pattern or dependency-injection friendly factory.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Daily Orchestrator Job Registration",
            "description": "Register a cron job that triggers the orchestrator at 10:00 AM local Jerusalem time with correct DST handling and 5-minute misfire grace.",
            "dependencies": [
              "15.1",
              "15.2"
            ],
            "details": "• Function `register_daily_job(scheduler, run_job)` in `core.py`.\n• Use `scheduler.add_job(run_job, 'cron', hour=10, minute=0, misfire_grace_time=300, id='daily_orchestrator')`.\n• Guard against duplicate job IDs when `register_daily_job` is called multiple times.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "CLI Entry Point & One-Shot Mode",
            "description": "Expose command `python -m alert_agent.scheduler --run_once` that either schedules normally or runs the orchestrator immediately for local testing.",
            "dependencies": [
              "15.3"
            ],
            "details": "• Module `alert_agent/scheduler/__main__.py` parses `--run_once` using argparse.\n• When flag present: call `asyncio.run(run_job())` and exit.\n• Otherwise: create scheduler, register job, keep event loop alive with `asyncio.Event().wait()`.",
            "status": "pending"
          },
          {
            "id": 6,
            "title": "Cleanup and Code Organization",
            "description": "Remove temporary files, organize imports, and ensure clean code structure",
            "details": "",
            "status": "pending",
            "dependencies": [
              "15.1",
              "15.2",
              "15.3",
              "15.4"
            ],
            "parentTaskId": 15
          },
          {
            "id": 8,
            "title": "Context7 MCP Research: External Package Dependencies",
            "description": "Use Context7 MCP to research and validate external Python packages and dependencies",
            "details": "",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 15
          },
          {
            "id": 9,
            "title": "Persistence & Graceful Shutdown",
            "description": "Persist scheduler within orchestrator process and handle SIGINT/SIGTERM for clean shutdown.",
            "details": "• Register signal.signal handlers that call await scheduler.shutdown(wait=False) and loop.stop()\n• Ensure orchestrator keeps a reference to the running scheduler for future job additions\n• Document manual test: TZ=Asia/Jerusalem python -m alert_agent.scheduler",
            "status": "pending",
            "dependencies": [
              "15.2",
              "15.3",
              "15.4"
            ],
            "parentTaskId": 15
          }
        ]
      },
      {
        "id": 16,
        "title": "Grafana MCP Alert Collector",
        "description": "Implement async data collector that fetches previous 24h alerts from Grafana MCP using httpx and returns normalised objects.",
        "details": "• Endpoint: `/api/alertmanager/grafana/api/v2/alerts?since=<iso>` (example; confirm via mcp.json). Use bearer token header.\n• Calculate `since = now - lookback_hours` in UTC; include timezone in query.\n• Design dataclass Alert(\n  id:str, service:str, severity:str, starts_at:dt, ends_at:Optional[dt], description:str, status:str)\n• Handle pagination (Grafana returns link header) with async recursion.\n• Retry w/ backoff on 5xx using backoff lib.\n",
        "priority": "high",
        "dependencies": [
          14
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Grafana MCP API specification & configuration",
            "description": "Research and verify the exact Grafana MCP Alertmanager endpoint, required query parameters, authentication method, and pagination link-header format. Capture example responses in fixtures and document environment variables (e.g., GRAFANA_MCP_TOKEN, GRAFANA_MCP_BASE_URL).",
            "dependencies": [],
            "details": "Deliver a concise API reference (endpoint paths, required headers, pagination scheme, rate limits) and create a typed settings object (pydantic BaseSettings) that loads base URL and bearer token from the environment or .env file.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Alert dataclass design & parsing helpers",
            "description": "Define the Alert dataclass and utility functions that map raw Grafana alert JSON into normalised Alert objects, handling optional fields and timezone-aware datetime parsing.",
            "dependencies": [
              "16.1"
            ],
            "details": "Implement Alert(id: str, service: str, severity: str, starts_at: datetime, ends_at: Optional[datetime], description: str, status: str). Provide from_grafana(payload: dict) -> Alert and list_from_response(resp_json: list) -> List[Alert]. Ensure all datetime values are converted to UTC and are tz-aware.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Async fetcher with lookback query construction",
            "description": "Implement an async function fetch_alert_page since=<iso> that builds the query using UTC now() - lookback_hours (default 24) and performs a single HTTP GET with httpx including bearer token header.",
            "dependencies": [
              "16.1"
            ],
            "details": "Use httpx.AsyncClient with a 10 s timeout. Compute since_iso = (datetime.utcnow() - timedelta(hours=lookback)).isoformat(timespec='seconds') + 'Z'. Return httpx.Response for further processing.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Pagination, retry/backoff, and aggregation to Alert objects",
            "description": "Compose the recursive collector that follows Link headers to fetch all pages, applies exponential backoff (backoff.on_exception) on 5xx, aggregates results, and returns List[Alert] using the parsing helpers.",
            "dependencies": [
              "16.2",
              "16.3"
            ],
            "details": "Implement async def collect_alerts(lookback_hours=24) -> List[Alert]. On each response, check response.headers['Link'] for rel=\"next\"; call itself until exhausted. Wrap network calls with backoff expo (max_tries=5, jitter). Transform each page’s JSON via list_from_response and extend the result list.",
            "status": "pending"
          },
          {
            "id": 6,
            "title": "Cleanup and Code Organization",
            "description": "Remove temporary files, organize imports, and ensure clean code structure",
            "details": "",
            "status": "pending",
            "dependencies": [
              "16.1",
              "16.2",
              "16.3",
              "16.4"
            ],
            "parentTaskId": 16
          },
          {
            "id": 8,
            "title": "Context7 MCP Research: External Package Dependencies",
            "description": "Use Context7 MCP to research and validate external Python packages and dependencies",
            "details": "",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 16
          }
        ]
      },
      {
        "id": 17,
        "title": "OpenRouter Claude 4 Sonnet Integration & Alert Grouping",
        "description": "Send collected alerts to Claude via OpenRouter for intelligent grouping and receive structured JSON clusters.",
        "details": "• Use https://openrouter.ai/api `POST /v1/chat/completions` with header `Authorization: Bearer <OPENROUTER_API_KEY>`.\n• Chat payload:\n  system: \"You are an SRE assistant. Respond ONLY with JSON...\"\n  user: provide alerts list & grouping instructions.\n• Use model `anthropic.claude-4-sonnet:beta` (as of 2024-06) `temperature=0.2`, `max_tokens=1024`.\n• Validate Claude response with pydantic model GroupedAlerts {groups: List[Group]} to catch hallucinations.\n• Fallback: If Claude fails validation, rerun with smaller chunk or mark ungrouped.\n",
        "priority": "high",
        "dependencies": [
          16
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "OpenRouter Client Setup",
            "description": "Create an async HTTP client that handles authentication, headers, and base URL for OpenRouter API calls.",
            "dependencies": [],
            "details": "• Use httpx.AsyncClient with a `Bearer <OPENROUTER_API_KEY>` header injected via environment variable.\n• Centralise endpoint `/v1/chat/completions`, default query params (temperature=0.2, max_tokens=1024, model=anthropic.claude-4-sonnet:beta).\n• Attach retry with exponential back-off for 429/5xx.\n• Ensure clean shutdown with async context manager.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Chat Payload Builder & Sender",
            "description": "Generate system/user messages from raw alerts and dispatch the request through the OpenRouter client.",
            "dependencies": [
              "17.1"
            ],
            "details": "• Accept List[Alert] and grouping instructions.\n• Compose JSON per OpenRouter spec with `system` and `user` keys.\n• Serialize alerts compactly to minimise tokens; include lookback window.\n• Invoke client from 17.1 and return raw Claude JSON string.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Response Parsing & Pydantic Validation",
            "description": "Validate Claude's JSON against the GroupedAlerts schema and convert it into domain objects.",
            "dependencies": [
              "17.2"
            ],
            "details": "• Define Pydantic models: Group, GroupedAlerts.\n• Load Claude raw text, strip code fences if present, then `json.loads`.\n• Raise ValidationError on schema mismatch or missing fields.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Fallback Chunking & Retry Logic",
            "description": "Implement recovery path when validation fails: split alerts into smaller batches or mark as ungrouped.",
            "dependencies": [
              "17.3"
            ],
            "details": "• On ValidationError, if alerts > threshold (e.g., 50), split list and recursively call 17.2.\n• Track recursion depth to avoid infinite loops.\n• If still invalid after max attempts, return fallback structure `{groups: []}` with all alerts ungrouped.",
            "status": "pending"
          },
          {
            "id": 5,
            "title": "End-to-End Orchestrator & Cost Guard",
            "description": "Tie everything together into a single `group_alerts(alerts: List[Alert]) -> GroupedAlerts` API with token cost monitoring.",
            "dependencies": [
              "17.1",
              "17.2",
              "17.3",
              "17.4"
            ],
            "details": "• Measure prompt + completion tokens using tiktoken or heuristic and compare against configured limit.\n• Log per-call cost estimate.\n• Provide high-level trace logs for debugging.\n• Expose as reusable library function for Task 18.",
            "status": "pending"
          },
          {
            "id": 6,
            "title": "Cleanup and Code Organization",
            "description": "Remove temporary files, organize imports, and ensure clean code structure",
            "details": "",
            "status": "pending",
            "dependencies": [
              "17.1",
              "17.2",
              "17.3",
              "17.4",
              "17.5"
            ],
            "parentTaskId": 17
          },
          {
            "id": 8,
            "title": "Context7 MCP Research: External Package Dependencies",
            "description": "Use Context7 MCP to research and validate external Python packages and dependencies",
            "details": "",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 17
          }
        ]
      },
      {
        "id": 18,
        "title": "Summary Generator & Formatter",
        "description": "Create human-readable markdown summary including executive overview, grouped details, and actionable items.",
        "details": "• Compose template with Jinja2==3.1.3:\n  - Executive metrics: total alerts, unique services, critical count\n  - Per-group bullet list with severity emoji (🔥 Critical, ⚠️ Warning)\n  - Resolution status table.\n• Inject Claude explanation: second Claude call (optional) to refine wording; reuse 17’s grouped data to keep token cost low.\n• Ensure Slack message ≤ 4000 chars; split threads if larger.\n",
        "priority": "medium",
        "dependencies": [
          17
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Markdown Jinja2 Template",
            "description": "Create a Jinja2 (v3.1.3) markdown template that includes an executive overview section (total alerts, unique services, critical count), per-group bullet lists with severity emojis, and a resolution-status table.",
            "dependencies": [],
            "details": "Save template under src/alert_agent/templates/summary.md.j2 with clear block names for optional sections.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Implement Summary Renderer",
            "description": "Write a Python function that loads grouped alert data from Task 17, populates the Jinja2 template, and returns raw markdown text.",
            "dependencies": [
              "18.1"
            ],
            "details": "Place implementation in src/alert_agent/summary.py; ensure minimal token footprint by passing pre-grouped data.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Add Optional Claude Refinement Step",
            "description": "Integrate an optional second Claude call that refines the generated markdown while maintaining token efficiency by sending only the rendered summary.",
            "dependencies": [
              "18.2"
            ],
            "details": "Expose flag refine_with_claude: bool; if true, call Claude and return its response; otherwise return original text.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Implement Slack Length Guard & Thread Splitter",
            "description": "Create utility that checks summary length (≤4000 chars) and, if exceeded, splits it into logically ordered thread messages.",
            "dependencies": [
              "18.3"
            ],
            "details": "Return List[str] ready for Task 19; preserve markdown integrity across splits.",
            "status": "pending"
          },
          {
            "id": 6,
            "title": "Cleanup and Code Organization",
            "description": "Remove temporary files, organize imports, and ensure clean code structure",
            "details": "",
            "status": "pending",
            "dependencies": [
              "18.1",
              "18.2",
              "18.3",
              "18.4"
            ],
            "parentTaskId": 18
          },
          {
            "id": 8,
            "title": "Context7 MCP Research: External Package Dependencies",
            "description": "Use Context7 MCP to research and validate external Python packages and dependencies",
            "details": "",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 18
          }
        ]
      },
      {
        "id": 19,
        "title": "Slack Notifier",
        "description": "Deliver summary to configured Slack channel with retries and thread support.",
        "details": "• Use Slack Web API `chat.postMessage` via httpx; endpoint `https://slack.com/api/chat.postMessage`.\n• Header `Authorization: Bearer xoxb-...`, `Content-Type: application/json`.\n• Payload: {channel: SLACK_CHANNEL_ID, text: summary, mrkdwn: true}.\n• If message > 4000 chars, split & post threaded replies using `thread_ts`.\n• Retry on `rate_limited` error with exponential backoff.\n",
        "priority": "high",
        "dependencies": [
          18,
          14
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Slack API Configuration",
            "description": "Provide secure configuration handling for Slack API credentials and channel ID.",
            "dependencies": [],
            "details": "• Read `SLACK_BOT_TOKEN` and `SLACK_CHANNEL_ID` from environment variables or a secrets manager.\n• Validate presence at application startup and raise descriptive error if missing.\n• Expose a dataclass/config object that downstream functions can import.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Low-level Slack `chat.postMessage` Client",
            "description": "Implement a reusable async function to call Slack `chat.postMessage` via httpx.",
            "dependencies": [
              "19.1"
            ],
            "details": "• Build request with header `Authorization: Bearer <token>` and `Content-Type: application/json`.\n• Accept params: channel, text, thread_ts (optional), mrkdwn (default true).\n• Return parsed JSON response and raise `SlackApiError` for non-ok replies (except 429 handled later).",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Message Splitting & Threaded Posting",
            "description": "Create helper that splits summaries >4000 characters and posts threaded replies.",
            "dependencies": [
              "19.2"
            ],
            "details": "• Determine Slack hard limit (4,000 chars).\n• Slice text at word boundaries; first chunk is root message, subsequent chunks posted with `thread_ts` of root.\n• Return array of message timestamps for possible auditing.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Exponential Backoff & Retry Logic",
            "description": "Add automatic retries for `rate_limited` (HTTP 429) responses with exponential backoff.",
            "dependencies": [
              "19.2",
              "19.3"
            ],
            "details": "• Detect 429 status or Slack JSON error `rate_limited`.\n• Implement backoff: start 1s, double each retry up to max 5 attempts.\n• Respect `Retry-After` header if present.\n• Make retry wrapper reusable around any Slack API call.",
            "status": "pending"
          },
          {
            "id": 6,
            "title": "Cleanup and Code Organization",
            "description": "Remove temporary files, organize imports, and ensure clean code structure",
            "details": "",
            "status": "pending",
            "dependencies": [
              "19.1",
              "19.2",
              "19.3",
              "19.4"
            ],
            "parentTaskId": 19
          },
          {
            "id": 8,
            "title": "Context7 MCP Research: External Package Dependencies",
            "description": "Use Context7 MCP to research and validate external Python packages and dependencies",
            "details": "",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 19
          }
        ]
      },
      {
        "id": 20,
        "title": "Unified Logging, Error Handling & Observability",
        "description": "Integrate Loguru for structured logs, add global exception handler and notification on failure.",
        "details": "• Configure Loguru to rotate daily, level=INFO.\n• Wrap each stage (collector, AI, notifier) in try/except; on fatal error send Slack DM to on-call via secondary Slack channel.\n• Create metrics counters (success, failure, duration) with Prometheus client (optional, lightweight) for future scraping.\n• Use backoff decorators for API interactions (max_tries=3).\n",
        "priority": "medium",
        "dependencies": [
          15,
          16,
          17,
          18,
          19
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure Loguru for Unified Structured Logging",
            "description": "Set up Loguru as the central logger with daily rotation and default level INFO for the entire service.",
            "dependencies": [],
            "details": "Add Loguru to requirements, create logging config module that initializes Loguru sink rotating at midnight (retention=7 days, compression=\"zip\"), set format to include timestamp, level, module, and json message field.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Implement Global Exception Handler with Loguru Integration",
            "description": "Install sys.excepthook override and asyncio exception handler to capture uncaught exceptions and log them via Loguru with stacktrace.",
            "dependencies": [
              "20.1"
            ],
            "details": "Create exception_handler.py; on exception, call logger.exception and re-raise or terminate gracefully; integrate handler in app entrypoint.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Add Slack DM Notification on Fatal Errors",
            "description": "On fatal errors captured by the global handler, post a direct message to the on-call engineer in a secondary Slack channel.",
            "dependencies": [
              "20.2"
            ],
            "details": "Use Slack Web API chat.postMessage with OAuth token from env; message includes service name, timestamp, and truncated traceback; retry with exponential backoff 3 attempts.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Integrate Prometheus Metrics Counters",
            "description": "Expose success, failure, and duration metrics for each stage (collector, AI, notifier) using the Prometheus client library.",
            "dependencies": [
              "20.1"
            ],
            "details": "Create metrics.py initializing Counter(success_total, failure_total) and Histogram(duration_seconds); expose /metrics endpoint via multiprocess if needed.",
            "status": "pending"
          },
          {
            "id": 5,
            "title": "Apply Backoff Decorators & Error-Aware Wrappers to All Stages",
            "description": "Wrap API interactions for collector, AI, and notifier with backoff.on_exception(max_tries=3) and ensure try/except blocks record metrics and trigger Slack alerts on unrecoverable errors.",
            "dependencies": [
              "20.2",
              "20.4"
            ],
            "details": "Refactor stage functions to decorator style; increment metrics in success/failure paths; on final failure call global handler which logs and notifies Slack.",
            "status": "pending"
          },
          {
            "id": 6,
            "title": "Cleanup and Code Organization",
            "description": "Remove temporary files, organize imports, and ensure clean code structure",
            "details": "",
            "status": "pending",
            "dependencies": [
              "20.1",
              "20.2",
              "20.3",
              "20.4",
              "20.5"
            ],
            "parentTaskId": 20
          },
          {
            "id": 8,
            "title": "Context7 MCP Research: External Package Dependencies",
            "description": "Use Context7 MCP to research and validate external Python packages and dependencies",
            "details": "",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 20
          }
        ]
      },
      {
        "id": 21,
        "title": "Orchestrator Assembly & CLI Entry Point",
        "description": "Glue scheduler, collector, AI processor, summary generator and notifier into a cohesive async workflow.",
        "details": "• `orchestrator.py` main async function:\n```\nasync def run_daily():\n    alerts = await collect_alerts()\n    grouped = await group_alerts(alerts)\n    summary = render_summary(grouped)\n    await send_slack(summary)\n```\n• Use `asyncio.run(run_daily())` for one-shot; expose `cli.py` with Typer==0.12.3 for commands `run-now`, `start-scheduler`.\n• Ensure graceful shutdown (scheduler.shutdown(wait=False)).\n",
        "priority": "high",
        "dependencies": [
          15,
          16,
          17,
          18,
          19,
          20
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement core async orchestrator logic",
            "description": "Create orchestrator.py with `async def run_daily()` that sequentially calls `collect_alerts`, `group_alerts`, `render_summary`, and `send_slack` using awaited coroutines.",
            "dependencies": [],
            "details": "Define type signatures, ensure each stage is injected via default parameters for testability, and propagate exceptions upwards without swallowing.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Add asyncio runner & graceful shutdown",
            "description": "Wrap `run_daily` in a `def run_now()` that calls `asyncio.run(run_daily())`; implement signal handlers (SIGINT, SIGTERM) that cancel pending tasks and ensure scheduler.shutdown(wait=False) if scheduler exists.",
            "dependencies": [
              "21.1"
            ],
            "details": "Use `asyncio.current_task().cancel()` on signal; include finally block to log completion; expose `shutdown()` helper.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Integrate daily scheduler",
            "description": "Create `start_scheduler()` that configures an APScheduler AsyncIOScheduler to trigger `run_daily` at 09:00 UTC (or configurable time) and starts the event loop until cancelled.",
            "dependencies": [
              "21.2"
            ],
            "details": "Add config for cron timing, pass coroutine reference, store scheduler instance globally for shutdown, and log job execution results.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Create Typer CLI entry point",
            "description": "Build cli.py with Typer==0.12.3 exposing `run-now` (calls run_now) and `start-scheduler` (calls start_scheduler). Provide --verbosity flag and auto-generated help.",
            "dependencies": [
              "21.3"
            ],
            "details": "Register app = Typer(); use `@app.command()` decorators; parse environment variables for config overrides; guard main block with `if __name__ == '__main__': app()`.",
            "status": "pending"
          },
          {
            "id": 5,
            "title": "End-to-end orchestration & CLI integration test",
            "description": "Develop comprehensive tests that spin up the CLI command in a subprocess with environment-defined mocks, verifying full pipeline execution and Slack notification call.",
            "dependencies": [
              "21.4"
            ],
            "details": "Use pytest’s `subprocess` fixture; inject fake HTTP server for collector, mock AI processor, capture stdout/stderr and exit code; ensure graceful exit on SIGTERM.",
            "status": "pending"
          },
          {
            "id": 6,
            "title": "Cleanup and Code Organization",
            "description": "Remove temporary files, organize imports, and ensure clean code structure",
            "details": "",
            "status": "pending",
            "dependencies": [
              "21.1",
              "21.2",
              "21.3",
              "21.4",
              "21.5"
            ],
            "parentTaskId": 21
          },
          {
            "id": 8,
            "title": "Context7 MCP Research: External Package Dependencies",
            "description": "Use Context7 MCP to research and validate external Python packages and dependencies",
            "details": "",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 21
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-07-29T15:57:21.028Z",
      "updated": "2025-07-30T14:56:05.844Z",
      "description": "Tasks for master context"
    }
  }
}
